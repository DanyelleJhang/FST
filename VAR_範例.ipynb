{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some example data\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "from statsmodels.tsa.vector_ar.var_model import VARResultsWrapper\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "from statsmodels.tsa.base.datetools import dates_from_str\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04 00:00:00+08:00</th>\n",
       "      <td>13.274090</td>\n",
       "      <td>13.274090</td>\n",
       "      <td>12.905365</td>\n",
       "      <td>12.905365</td>\n",
       "      <td>24549000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05 00:00:00+08:00</th>\n",
       "      <td>12.905366</td>\n",
       "      <td>13.163474</td>\n",
       "      <td>12.757876</td>\n",
       "      <td>12.794749</td>\n",
       "      <td>27544000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06 00:00:00+08:00</th>\n",
       "      <td>12.831620</td>\n",
       "      <td>12.905365</td>\n",
       "      <td>12.757874</td>\n",
       "      <td>12.757874</td>\n",
       "      <td>18716000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07 00:00:00+08:00</th>\n",
       "      <td>12.757875</td>\n",
       "      <td>12.905365</td>\n",
       "      <td>12.573512</td>\n",
       "      <td>12.868493</td>\n",
       "      <td>24452000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08 00:00:00+08:00</th>\n",
       "      <td>12.757873</td>\n",
       "      <td>12.942235</td>\n",
       "      <td>12.647256</td>\n",
       "      <td>12.831618</td>\n",
       "      <td>20183000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-19 00:00:00+08:00</th>\n",
       "      <td>23.450001</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>23.350000</td>\n",
       "      <td>22809555</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-22 00:00:00+08:00</th>\n",
       "      <td>23.250000</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>26506583</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-23 00:00:00+08:00</th>\n",
       "      <td>23.100000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>23.150000</td>\n",
       "      <td>15851825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-26 00:00:00+08:00</th>\n",
       "      <td>23.049999</td>\n",
       "      <td>23.049999</td>\n",
       "      <td>22.799999</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>36089954</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-29 00:00:00+08:00</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>22.850000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>13773319</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2082 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2016-01-04 00:00:00+08:00  13.274090  13.274090  12.905365  12.905365   \n",
       "2016-01-05 00:00:00+08:00  12.905366  13.163474  12.757876  12.794749   \n",
       "2016-01-06 00:00:00+08:00  12.831620  12.905365  12.757874  12.757874   \n",
       "2016-01-07 00:00:00+08:00  12.757875  12.905365  12.573512  12.868493   \n",
       "2016-01-08 00:00:00+08:00  12.757873  12.942235  12.647256  12.831618   \n",
       "...                              ...        ...        ...        ...   \n",
       "2024-07-19 00:00:00+08:00  23.450001  23.500000  23.100000  23.350000   \n",
       "2024-07-22 00:00:00+08:00  23.250000  23.299999  23.000000  23.100000   \n",
       "2024-07-23 00:00:00+08:00  23.100000  23.250000  23.100000  23.150000   \n",
       "2024-07-26 00:00:00+08:00  23.049999  23.049999  22.799999  22.900000   \n",
       "2024-07-29 00:00:00+08:00  23.000000  23.000000  22.850000  22.900000   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2016-01-04 00:00:00+08:00  24549000       0.00           0.0  \n",
       "2016-01-05 00:00:00+08:00  27544000       0.00           0.0  \n",
       "2016-01-06 00:00:00+08:00  18716000       0.00           0.0  \n",
       "2016-01-07 00:00:00+08:00  24452000       0.00           0.0  \n",
       "2016-01-08 00:00:00+08:00  20183000       0.00           0.0  \n",
       "...                             ...        ...           ...  \n",
       "2024-07-19 00:00:00+08:00  22809555       0.00           0.0  \n",
       "2024-07-22 00:00:00+08:00  26506583       0.00           0.0  \n",
       "2024-07-23 00:00:00+08:00  15851825       0.00           0.0  \n",
       "2024-07-26 00:00:00+08:00  36089954       0.35           0.0  \n",
       "2024-07-29 00:00:00+08:00  13773319       0.00           0.0  \n",
       "\n",
       "[2082 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# 2023.TW 燁輝\n",
    "# 2002.TW 中鋼\n",
    "# 2006.TW 中和鋼鐵\n",
    "# 2007.TW 燁興\n",
    "date = '2016-01-01'\n",
    "stock_no = '2002.TW'\n",
    "\n",
    "stock = yf.Ticker(stock_no)\n",
    "data = stock.history(start=date)\n",
    "\n",
    "data#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(dir+\"National Stock Exchange/infy_stock.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# 要把 dataframe 的格式清理成以下格式\n",
    "# dates_from_str 要放入 index\n",
    "# 剩下的資料只能保留 feature\n",
    "# \"\"\"\n",
    "# # statsmodels的範例資料\n",
    "# import statsmodels.api as sm\n",
    "# mdata = sm.datasets.macrodata.load_pandas().data\n",
    "# mdata\n",
    "# dates = mdata[['year', 'quarter']].astype(int).astype(str)\n",
    "# quarterly = dates[\"year\"] + \"Q\" + dates[\"quarter\"]\n",
    "# quarterly = dates_from_str(quarterly)\n",
    "# mdata.index = pd.DatetimeIndex(quarterly)\n",
    "# data = mdata.drop(columns=[\"year\",\"quarter\"])\n",
    "# data\n",
    "\n",
    "# # KAGGLE 範例資料 1 \n",
    "# dir = \"C:/Users/foresight_User/Desktop/公司文件/9.產品/AIUPS/\"\n",
    "# data = pd.read_csv(dir+\"National Stock Exchange/infy_stock.csv\")\n",
    "# data.index =pd.DatetimeIndex(dates_from_str(data[\"Date\"]))\n",
    "# data = data.drop(columns=[\"Date\",\"Symbol\",\"Series\"])\n",
    "# data\n",
    "\n",
    "# # KAGGLE 範例資料 2\n",
    "# data = pd.read_csv(dir+\"National Stock Exchange/nifty_it_index.csv\")\n",
    "# data.index =pd.DatetimeIndex(dates_from_str(data[\"Date\"]))\n",
    "# data = data.drop(columns=[\"Date\"])\n",
    "# data\n",
    "\n",
    "# # KAGGLE 範例資料 3\n",
    "# data = pd.read_csv(dir+\"National Stock Exchange/tcs_stock.csv\")\n",
    "# data.index =pd.DatetimeIndex(dates_from_str(data[\"Date\"]))\n",
    "# data = data.drop(columns=[\"Date\",\"Symbol\",\"Series\"])\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_format_preprocessing(df:pd.DataFrame, datetime_col:str):\n",
    "    #\n",
    "    # YS(年初), MS(月初), W(周), D(日), H(小時), T(分鐘), S(秒),\n",
    "    #\n",
    "    # df = df.copy()\n",
    "    # df[datetime_col] = pd.to_datetime(df[datetime_col], format='%Y-%m-%d %H:%M:%S')\n",
    "    # df = df.set_index(datetime_col)\n",
    "    # df = df.asfreq(interval)\n",
    "    # return df if set_index_flag else df.reset_index(drop=False)\n",
    "    df.index =pd.DatetimeIndex(dates_from_str(data[datetime_col]))\n",
    "    df = df.drop(columns=[datetime_col])\n",
    "    \"\"\"\n",
    "    Imputes missing values in a time series DataFrame using the specified function.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing the time series data.\n",
    "        func (str): The imputation function to be applied. Supported options are:\n",
    "                    - 'forward_fill': Forward fill missing values.\n",
    "                    - 'backward_fill': Backward fill missing values.\n",
    "                    - 'moving_average': Impute missing values using moving average.\n",
    "                    - 'interpolation': Perform linear interpolation to fill missing values.\n",
    "        col_name (str): The name of the column to impute missing values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with missing values imputed based on the specified function.\n",
    "    \"\"\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def time_series_impute_missing_value(df, func, col_name):\n",
    "    \"\"\"\n",
    "    Imputes missing values in a time series DataFrame using the specified function.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing the time series data.\n",
    "        func (str): The imputation function to be applied. Supported options are:\n",
    "                    - 'forward_fill': Forward fill missing values.\n",
    "                    - 'backward_fill': Backward fill missing values.\n",
    "                    - 'moving_average': Impute missing values using moving average.\n",
    "                    - 'interpolation': Perform linear interpolation to fill missing values.\n",
    "        col_name (str): The name of the column to impute missing values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with missing values imputed based on the specified function.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if func == 'forward_fill':\n",
    "        df[col_name].ffill(inplace=True)\n",
    "    elif func == 'backward_fill':\n",
    "        df[col_name].bfill(inplace=True)\n",
    "    elif func == 'moving_average':\n",
    "        df[col_name].fillna(df[col_name].rolling(window=3, min_periods=1).mean(), inplace=True)\n",
    "    elif func == 'interpolation':\n",
    "        df[col_name].interpolate(inplace=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported imputation function: {func}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 這邊不要動 =====\n",
    "\n",
    "# \"\"\" \n",
    "# 這是套件設定的\n",
    "# trend : str {\"n\", \"c\", \"ct\", \"ctt\"}\n",
    "#     * \"n\" - no deterministic terms\n",
    "#     * \"c\" - constant term\n",
    "#     * \"ct\" - constant and linear term\n",
    "#     * \"ctt\" - constant, linear, and quadratic term\n",
    "\n",
    "# maxlags 不可以超過 max_estimable 的值\n",
    "# maxlags 為模型擬合最大數值\n",
    "# statemodel有設定條件，已經寫在下述的程式\n",
    "# 使用者要調整低於 maxlags\n",
    "# \"\"\"\n",
    "# max_estimable = cal_maxLag(data)\n",
    "# # ==== 這邊不要動 =====\n",
    "\n",
    "# print(\" maxlags 要小於等於: \", max_estimable)\n",
    "\n",
    "# if maxlags == \"auto\":\n",
    "#     maxlags = max_estimable\n",
    "# if maxlags > max_estimable:\n",
    "#     raise Exception(\" maxlags 要小於等於: \", max_estimable)\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# ic 為評估模型的好壞\n",
    "# ic = {'aic', 'fpe', 'hqic', 'bic', None}\n",
    "# Information criterion to use for VAR order selection.\n",
    "# aic : Akaike\n",
    "# fpe : Final prediction error\n",
    "# hqic : Hannan-Quinn\n",
    "# bic : Bayesian a.k.a. Schwarz\n",
    "# \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_maxLag(data:pd.DataFrame):\n",
    "    n_totobs = len(data)\n",
    "    ntrend = 1 #len(trend) if trend.startswith(\"c\") else 0\n",
    "    neqs = data.shape[1]\n",
    "    max_estimable = (n_totobs - neqs - ntrend) // (1 + neqs)\n",
    "    if max_estimable > 1:\n",
    "        return max_estimable\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorAutoregression(data:pd.DataFrame,maxlags:Union[int,str]=\"auto\",ic:str=None):\n",
    "    model = VAR(data)\n",
    "    # ==== 這邊不要動 =====\n",
    "\n",
    "    \"\"\" \n",
    "    這是套件設定的\n",
    "    trend : str {\"n\", \"c\", \"ct\", \"ctt\"}\n",
    "        * \"n\" - no deterministic terms\n",
    "        * \"c\" - constant term\n",
    "        * \"ct\" - constant and linear term\n",
    "        * \"ctt\" - constant, linear, and quadratic term\n",
    "\n",
    "    maxlags 不可以超過 max_estimable 的值\n",
    "    maxlags 為模型擬合最大數值\n",
    "    statemodel有設定條件，已經寫在下述的程式\n",
    "    使用者要調整低於 maxlags\n",
    "    \"\"\"\n",
    "    max_estimable = cal_maxLag(data)\n",
    "    # ==== 這邊不要動 =====\n",
    "\n",
    "    print(\" maxlags 要小於等於: \", max_estimable)\n",
    "\n",
    "    if maxlags == \"auto\":\n",
    "        maxlags = max_estimable\n",
    "    if maxlags > max_estimable:\n",
    "        raise Exception(\" maxlags 要小於等於: \", max_estimable)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ic 為評估模型的好壞\n",
    "    ic = {'aic', 'fpe', 'hqic', 'bic', None}\n",
    "    Information criterion to use for VAR order selection.\n",
    "    aic : Akaike\n",
    "    fpe : Final prediction error\n",
    "    hqic : Hannan-Quinn\n",
    "    bic : Bayesian a.k.a. Schwarz\n",
    "    \"\"\"\n",
    "\n",
    "    results = model.fit(maxlags=maxlags, ic=ic)\n",
    "    print(f\"在最大 lag 數目為 {max_estimable} 的情況下，VAR 找出的最佳 lag 為: \",results.k_ar)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorAutoregressionRelationship(results:VARResultsWrapper,target:str,pvalue_threshold:float=0.05):\n",
    "    # target  客人關心的 Y 是甚麼，Y 會包含在 results 中\n",
    "\n",
    "    coef_df = results.params[target]\n",
    "    pvalues_df = results.pvalues[target]\n",
    "\n",
    "    # 合并系数和p值\n",
    "    summary = pd.concat([coef_df, pvalues_df], axis=1)\n",
    "    summary.columns = ['coef', 'pvalue']\n",
    "    summary = summary.drop(index=\"const\").reset_index()\n",
    "    summary_index = summary[\"index\"].str.split(\".\", expand=True).rename(columns={0:\"time_lag\",1:\"feature\"})\n",
    "    if summary.empty:\n",
    "        return {\"info\":\"there is no results found from VAR\"}\n",
    "    else:\n",
    "        summary_index[\"time_lag\"] = summary_index[\"time_lag\"].str.replace(\"L\",\"\").astype(int)\n",
    "        summary = pd.concat([summary_index,summary],axis=1).drop(columns=\"index\")\n",
    "        summary = summary[summary[\"pvalue\"]<pvalue_threshold].reset_index(drop=True)\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foresight_User\\AppData\\Local\\Temp\\ipykernel_17380\\1254553657.py:14: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_data = data.resample('M').agg(aggregation_functions)\n",
      "C:\\Users\\foresight_User\\AppData\\Local\\Temp\\ipykernel_17380\\1254553657.py:15: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  yearly_data = data.resample('Y').agg(aggregation_functions)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 定義聚合函數和相應的列名\n",
    "operator_list = ['first', 'last', 'mean','prod','median','max','min']#'std','max','count','sum',\"min\",\"prod\",\"median\",\"var\",\"sem\",\"skew\",\"cumsum\",\"cumprod\"]\n",
    "\n",
    "\n",
    "aggregation_functions = {}\n",
    "for i in data.columns:\n",
    "    aggregation_functions[i]=operator_list\n",
    "\n",
    "# 按週重採樣並應用聚合\n",
    "weekly_data = data.resample('W').agg(aggregation_functions)\n",
    "\n",
    "# 自定義列名\n",
    "\n",
    "monthly_data = data.resample('M').agg(aggregation_functions)\n",
    "yearly_data = data.resample('Y').agg(aggregation_functions)\n",
    "\n",
    "weekly_data.columns = ['_'.join(col).strip() for col in weekly_data.columns.values]\n",
    "monthly_data.columns = ['_'.join(col).strip() for col in monthly_data.columns.values]\n",
    "yearly_data.columns = ['_'.join(col).strip() for col in yearly_data.columns.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_collinearity(data,remain:list=None): #condition\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    if remain != None:\n",
    "        remained_data = data.loc[:,remain]\n",
    "        data = data.drop(columns=remain)\n",
    "    #data = data.fillna(method='ffill').fillna(method='bfill')\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.ffill().bfill() \n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = data.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(data.values, i) for i in range(len(data.columns))]\n",
    "\n",
    "\n",
    "    # 去除VIF為NAN或INF\n",
    "    vif_data = vif_data.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "    data = data[vif_data[\"feature\"].to_list()]\n",
    "\n",
    "    # 移除高相關的 feature \n",
    "    # 保留低相關的 feature\n",
    "    coefficient_threshold = 0.3\n",
    "    correlation_matrix = data.corr()\n",
    "    low_corr_vars = np.where(np.abs(correlation_matrix) < coefficient_threshold)\n",
    "    #print(correlation_matrix)\n",
    "    low_corr_vars = [(correlation_matrix.index[x], correlation_matrix.columns[y]) for x, y in zip(*low_corr_vars) if x != y and x > y]\n",
    "\n",
    "    # Remove one of each highly correlated pair\n",
    "    # if condition == \"intersection\":\n",
    "    #     sets =  [set(pair) for pair in low_corr_vars]\n",
    "    #     intersection = set.intersection(*sets)\n",
    "    #     remaining_list = list(intersection)\n",
    "    # if condition == \"union\":\n",
    "    unique_elements = set(element for pair in low_corr_vars for element in pair)\n",
    "    remaining_list = list(unique_elements)\n",
    "    \n",
    "    data = data[remaining_list]\n",
    "    if remain != None:\n",
    "        data = pd.concat([data,remained_data],axis=1)\n",
    "    # impute nan\n",
    "    #data = data.fillna(method='ffill').fillna(method='bfill')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividends_max\n",
      "296\n",
      " maxlags 要小於等於:  296\n",
      "在最大 lag 數目為 296 的情況下，VAR 找出的最佳 lag 為:  3\n",
      "Open\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\foresight_User\\anaconda3\\envs\\Python3.9.13\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\foresight_User\\anaconda3\\envs\\Python3.9.13\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\foresight_User\\anaconda3\\envs\\Python3.9.13\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      " maxlags 要小於等於:  9\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge in Linear Least Squares",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 26\u001b[0m\n\u001b[0;32m     21\u001b[0m maxlags \u001b[38;5;241m=\u001b[39m cal_maxLag(clean_data) \u001b[38;5;66;03m# USER 不能指定超過這個的LAG，LAG值也要大於0\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(maxlags)\n\u001b[1;32m---> 26\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvectorAutoregression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaxlags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m pvalue_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[0;32m     28\u001b[0m VAR_relationship \u001b[38;5;241m=\u001b[39m vectorAutoregressionRelationship(results\u001b[38;5;241m=\u001b[39mresults,target\u001b[38;5;241m=\u001b[39mtarget,pvalue_threshold\u001b[38;5;241m=\u001b[39mpvalue_threshold)\n",
      "Cell \u001b[1;32mIn[36], line 39\u001b[0m, in \u001b[0;36mvectorAutoregression\u001b[1;34m(data, maxlags, ic)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m maxlags 要小於等於: \u001b[39m\u001b[38;5;124m\"\u001b[39m, max_estimable)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03mic 為評估模型的好壞\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03mic = {'aic', 'fpe', 'hqic', 'bic', None}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03mbic : Bayesian a.k.a. Schwarz\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxlags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m在最大 lag 數目為 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_estimable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 的情況下，VAR 找出的最佳 lag 為: \u001b[39m\u001b[38;5;124m\"\u001b[39m,results\u001b[38;5;241m.\u001b[39mk_ar)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\foresight_User\\anaconda3\\envs\\Python3.9.13\\lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py:694\u001b[0m, in \u001b[0;36mVAR.fit\u001b[1;34m(self, maxlags, method, ic, trend, verbose)\u001b[0m\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mxnames \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    687\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mxnames[:k_trend]\n\u001b[0;32m    688\u001b[0m         \u001b[38;5;241m+\u001b[39m x_names_to_add\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mxnames[k_trend:]\n\u001b[0;32m    690\u001b[0m     )\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcov_names \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_product(\n\u001b[0;32m    692\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mxnames, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mynames)\n\u001b[0;32m    693\u001b[0m )\n\u001b[1;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\foresight_User\\anaconda3\\envs\\Python3.9.13\\lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py:742\u001b[0m, in \u001b[0;36mVAR._estimate_var\u001b[1;34m(self, lags, offset, trend)\u001b[0m\n\u001b[0;32m    740\u001b[0m y_sample \u001b[38;5;241m=\u001b[39m endog[lags:]\n\u001b[0;32m    741\u001b[0m \u001b[38;5;66;03m# Lütkepohl p75, about 5x faster than stated formula\u001b[39;00m\n\u001b[1;32m--> 742\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-15\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    743\u001b[0m resid \u001b[38;5;241m=\u001b[39m y_sample \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(z, params)\n\u001b[0;32m    745\u001b[0m \u001b[38;5;66;03m# Unbiased estimate of covariance matrix $\\Sigma_u$ of the white noise\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# process $u$\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# equivalent definition\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;66;03m# Ref: Lütkepohl p.75\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;66;03m# df_resid right now is T - Kp - 1, which is a suggested correction\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\foresight_User\\anaconda3\\envs\\Python3.9.13\\lib\\site-packages\\numpy\\linalg\\linalg.py:2326\u001b[0m, in \u001b[0;36mlstsq\u001b[1;34m(a, b, rcond)\u001b[0m\n\u001b[0;32m   2323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_rhs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2324\u001b[0m     \u001b[38;5;66;03m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[39;00m\n\u001b[0;32m   2325\u001b[0m     b \u001b[38;5;241m=\u001b[39m zeros(b\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (m, n_rhs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mb\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m-> 2326\u001b[0m x, resids, rank, s \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2328\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\foresight_User\\anaconda3\\envs\\Python3.9.13\\lib\\site-packages\\numpy\\linalg\\linalg.py:124\u001b[0m, in \u001b[0;36m_raise_linalgerror_lstsq\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_lstsq\u001b[39m(err, flag):\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge in Linear Least Squares\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: SVD did not converge in Linear Least Squares"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "讓使用者決定好奇的target是甚麼，套件會自動找出所有跟target相關的不同time lag的時間變相\n",
    "maxlags 會影響最終最佳推薦的結果，也得慎選，但設定上不可以超過 cal_maxLag 輸出的值\n",
    "\"\"\"\n",
    "# #data = pd.read_csv(dir+\"National Stock Exchange/tcs_stock.csv\").drop(columns=[\"Symbol\",\"Series\"])\n",
    "# data = time_series_format_preprocessing(data,\"Date\")\n",
    "# data = time_series_impute_missing_value(data, 'interpolation', \"Volume\")\n",
    "\n",
    "# 如果有缺失值，可以选择填充或删除\n",
    "\n",
    "\n",
    "# \n",
    "# \n",
    "# \n",
    "\n",
    "for d in [data,weekly_data,monthly_data,yearly_data]:\n",
    "    for i in d.columns:\n",
    "        print(target)\n",
    "        target = i #\"Open_first\"#\"Trades\"\n",
    "        clean_data = remove_collinearity(data=d,remain=[target])\n",
    "        maxlags = cal_maxLag(clean_data) # USER 不能指定超過這個的LAG，LAG值也要大於0\n",
    "        print(maxlags)\n",
    "        results = vectorAutoregression(clean_data,maxlags=3,ic=None)\n",
    "        pvalue_threshold = 0.05\n",
    "        VAR_relationship = vectorAutoregressionRelationship(results=results,target=target,pvalue_threshold=pvalue_threshold)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Open_first'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_lag</th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Open_min</td>\n",
       "      <td>3.860940e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Close_last</td>\n",
       "      <td>2.649091e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Open_max</td>\n",
       "      <td>-2.781502e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Close_min</td>\n",
       "      <td>3.438232e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Volume_last</td>\n",
       "      <td>-4.559469e-08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Volume_mean</td>\n",
       "      <td>-4.983963e-08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Low_min</td>\n",
       "      <td>3.127998e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Low_median</td>\n",
       "      <td>-2.396077e-03</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Volume_first</td>\n",
       "      <td>-2.419460e-08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Close_first</td>\n",
       "      <td>-3.561709e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Low_first</td>\n",
       "      <td>-2.977893e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Volume_max</td>\n",
       "      <td>2.220230e-09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Open_last</td>\n",
       "      <td>2.766122e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>High_first</td>\n",
       "      <td>-2.987857e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>Volume_min</td>\n",
       "      <td>1.184669e-07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>Open_median</td>\n",
       "      <td>-2.019543e-03</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>Open_first</td>\n",
       "      <td>-2.522345e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_lag       feature          coef    pvalue\n",
       "0          1      Open_min  3.860940e-02  0.000000\n",
       "1          1    Close_last  2.649091e-02  0.000000\n",
       "2          1      Open_max -2.781502e-02  0.000000\n",
       "3          1     Close_min  3.438232e-02  0.000000\n",
       "4          1   Volume_last -4.559469e-08  0.000000\n",
       "5          1   Volume_mean -4.983963e-08  0.000000\n",
       "6          1       Low_min  3.127998e-02  0.000000\n",
       "7          1    Low_median -2.396077e-03  0.000093\n",
       "8          1  Volume_first -2.419460e-08  0.000000\n",
       "9          1   Close_first -3.561709e-02  0.000000\n",
       "10         1     Low_first -2.977893e-02  0.000000\n",
       "11         1    Volume_max  2.220230e-09  0.000000\n",
       "12         1     Open_last  2.766122e-02  0.000000\n",
       "13         1    High_first -2.987857e-02  0.000000\n",
       "14         1    Volume_min  1.184669e-07  0.000000\n",
       "15         1   Open_median -2.019543e-03  0.000123\n",
       "16         1    Open_first -2.522345e-02  0.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Open_max'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2,\"time_lag\"]\n",
    "df.loc[2,\"feature\"]#[\"feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['TIME'] = pd.to_datetime(df['TIME'])\n",
    "\n",
    "# 添加 X_1 的 time lag 1 和 2\n",
    "df['X_1_lag1'] = df['X_1'].shift(1)\n",
    "df['X_1_lag2'] = df['X_1'].shift(2)\n",
    "\n",
    "# 添加 X_2 的 time lag 4\n",
    "df['X_2_lag4'] = df['X_2'].shift(4)\n",
    "\n",
    "# 將 TIME 設為索引（可選）\n",
    "df.set_index('TIME', inplace=True)\n",
    "\n",
    "# 移除包含 NaN 值的行\n",
    "#df.dropna(inplace=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = results.params[target]\n",
    "pvalues_df = results.pvalues[target]\n",
    "\n",
    "# 合并系数和p值\n",
    "summary = pd.concat([coef_df, pvalues_df], axis=1)\n",
    "summary.columns = ['coef', 'pvalue']\n",
    "summary = summary.drop(index=\"const\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VAR_relationship' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mVAR_relationship\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VAR_relationship' is not defined"
     ]
    }
   ],
   "source": [
    "VAR_relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04 00:00:00+08:00</th>\n",
       "      <td>13.274089</td>\n",
       "      <td>13.274089</td>\n",
       "      <td>12.905364</td>\n",
       "      <td>12.905364</td>\n",
       "      <td>24549000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05 00:00:00+08:00</th>\n",
       "      <td>12.905366</td>\n",
       "      <td>13.163474</td>\n",
       "      <td>12.757876</td>\n",
       "      <td>12.794749</td>\n",
       "      <td>27544000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06 00:00:00+08:00</th>\n",
       "      <td>12.831618</td>\n",
       "      <td>12.905363</td>\n",
       "      <td>12.757873</td>\n",
       "      <td>12.757873</td>\n",
       "      <td>18716000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07 00:00:00+08:00</th>\n",
       "      <td>12.757874</td>\n",
       "      <td>12.905364</td>\n",
       "      <td>12.573511</td>\n",
       "      <td>12.868492</td>\n",
       "      <td>24452000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08 00:00:00+08:00</th>\n",
       "      <td>12.757874</td>\n",
       "      <td>12.942236</td>\n",
       "      <td>12.647257</td>\n",
       "      <td>12.831619</td>\n",
       "      <td>20183000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-19 00:00:00+08:00</th>\n",
       "      <td>23.450001</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>23.350000</td>\n",
       "      <td>22809555</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-22 00:00:00+08:00</th>\n",
       "      <td>23.250000</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>26506583</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-23 00:00:00+08:00</th>\n",
       "      <td>23.100000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>23.150000</td>\n",
       "      <td>15851825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-26 00:00:00+08:00</th>\n",
       "      <td>23.049999</td>\n",
       "      <td>23.049999</td>\n",
       "      <td>22.799999</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>36089954</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-29 00:00:00+08:00</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>22.850000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>2420972</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2082 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2016-01-04 00:00:00+08:00  13.274089  13.274089  12.905364  12.905364   \n",
       "2016-01-05 00:00:00+08:00  12.905366  13.163474  12.757876  12.794749   \n",
       "2016-01-06 00:00:00+08:00  12.831618  12.905363  12.757873  12.757873   \n",
       "2016-01-07 00:00:00+08:00  12.757874  12.905364  12.573511  12.868492   \n",
       "2016-01-08 00:00:00+08:00  12.757874  12.942236  12.647257  12.831619   \n",
       "...                              ...        ...        ...        ...   \n",
       "2024-07-19 00:00:00+08:00  23.450001  23.500000  23.100000  23.350000   \n",
       "2024-07-22 00:00:00+08:00  23.250000  23.299999  23.000000  23.100000   \n",
       "2024-07-23 00:00:00+08:00  23.100000  23.250000  23.100000  23.150000   \n",
       "2024-07-26 00:00:00+08:00  23.049999  23.049999  22.799999  22.900000   \n",
       "2024-07-29 00:00:00+08:00  23.000000  23.000000  22.850000  22.900000   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2016-01-04 00:00:00+08:00  24549000       0.00           0.0  \n",
       "2016-01-05 00:00:00+08:00  27544000       0.00           0.0  \n",
       "2016-01-06 00:00:00+08:00  18716000       0.00           0.0  \n",
       "2016-01-07 00:00:00+08:00  24452000       0.00           0.0  \n",
       "2016-01-08 00:00:00+08:00  20183000       0.00           0.0  \n",
       "...                             ...        ...           ...  \n",
       "2024-07-19 00:00:00+08:00  22809555       0.00           0.0  \n",
       "2024-07-22 00:00:00+08:00  26506583       0.00           0.0  \n",
       "2024-07-23 00:00:00+08:00  15851825       0.00           0.0  \n",
       "2024-07-26 00:00:00+08:00  36089954       0.35           0.0  \n",
       "2024-07-29 00:00:00+08:00   2420972       0.00           0.0  \n",
       "\n",
       "[2082 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fVolume_min(t) = 1.100 * Volume_min(t-1) -  210634.048 * High_first(t-1) + 166969.493 * Low_last(t-1) + 1.491 * Volume_median(t-1) + 0.310 * Volume_first(t-1) -  199683.404 * Close_max(t-1) -  1.684 * Volume_mean(t-1) + 155007.475 * High_last(t-1) -  195455.261 * Open_max(t-1) -  248780.777 * Close_first(t-1) -  32629.428 * Open_median(t-1) + 0.157 * Volume_max(t-1) + 3534.103 * Low_mean(t-1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "生成VAR關係公式\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "可有可無，看需求\n",
    "\"\"\"\n",
    "formula_parts = []\n",
    "for index, row in VAR_relationship.iterrows():\n",
    "    coef = row['coef']\n",
    "    if coef < 0:\n",
    "        term = f\"- {-coef:.3f} * {row['feature']}(t-{row['time_lag']})\"\n",
    "    else:\n",
    "        term = f\"{coef:.3f} * {row['feature']}(t-{row['time_lag']})\"\n",
    "    formula_parts.append(term)\n",
    "\n",
    "formula = \" + \".join(formula_parts).replace(\"+ -\", \"- \")\n",
    "target_formula = f\"f{target}(t) = {formula}\"\n",
    "\n",
    "# 打印公式\n",
    "print(target_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_format_preprocessing(df: pd.DataFrame, interval, datetime_col, set_index_flag=False):\n",
    "    #\n",
    "    # YS(年初), MS(月初), W(周), D(日), H(小時), T(分鐘), S(秒),\n",
    "    #\n",
    "    df = df.copy()\n",
    "    df[datetime_col] = pd.to_datetime(df[datetime_col], format='%Y-%m-%d %H:%M:%S')\n",
    "    df = df.dropna(subset=[datetime_col])\n",
    "    # 方法1\n",
    "    # df = df.set_index(datetime_col)\n",
    "    # df = df[~df.index.duplicated(keep='first')]\n",
    "    # df = df.asfreq(interval)\n",
    "    # return df if set_index_flag else df.reset_index(drop=False)\n",
    "\n",
    "    # 方法2\n",
    "    df = df.set_index(datetime_col, append=True)\n",
    "    def asfreq(df, freq):\n",
    "        # 防止索引名稱為null\n",
    "        names = []\n",
    "        for i, name in enumerate(df.index.names):\n",
    "            if name is None:\n",
    "                names.append(f\"level_{i}\")\n",
    "            else:\n",
    "                names.append(name)\n",
    "        df.index.names = names\n",
    "        # 重設第一個索引層級\n",
    "        level_to_reset = df.index.names[0]\n",
    "        df_reset = df.reset_index(level=level_to_reset)\n",
    "        df_reset = df_reset[~df_reset.index.duplicated(keep='first')]\n",
    "        # 重新設置頻率\n",
    "        df_resampled = df_reset.asfreq(freq)\n",
    "        df_resampled.reset_index(inplace=True) # 會導致freq設定消失\n",
    "        # 設置新的索引\n",
    "        for i, name in enumerate(df.index.names):\n",
    "            df_resampled.set_index(name, inplace=True, append=True if i > 0 else False)\n",
    "        return df_resampled\n",
    "\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    df = asfreq(df, interval)\n",
    "\n",
    "    df.index.levels[1].freq = interval\n",
    "    return df if set_index_flag else df.reset_index(drop=False, level=df.index.names[1]) # 0是原索引，1是時間索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_series_format_preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtime_series_format_preprocessing\u001b[49m(data\u001b[38;5;241m.\u001b[39mreset_index(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1W\u001b[39m\u001b[38;5;124m\"\u001b[39m,datetime_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time_series_format_preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "time_series_format_preprocessing(data.reset_index(),\"1W\",datetime_col=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39masfreq(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1W\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.asfreq(\"1W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
